---
title: "FAQ"
description: "Frequently asked questions"
icon: "question"
iconType: "solid"
---

## FAQ

### What file types does Mixpeek support?

Mixpeek supports extraction and searching of the most popular file types and many others:

<CardGroup cols={2}>
  <Card
    title="Text"
    icon="file-pdf"
    color="#ea5a0c"
    href="https://mixpeek.com/files/pdf"
  >
    Find the exact page where your text exists
  </Card>
  <Card
    title="Image"
    icon="file-image"
    color="#0285c7"
    href="https://mixpeek.com/files/png"
  >
    Discover the pictures that contain your search
  </Card>
  <Card
    title="Video"
    icon="file-video"
    color="#dc2626"
    href="https://mixpeek.com/files/mp4"
  >
    See the exact frames where your words are shown
  </Card>
  <Card
    title="Audio"
    icon="file-music"
    color="#16a34a"
    href="https://mixpeek.com/files/mp3"
  >
    Find the timestamp where your term is mentioned
  </Card>
</CardGroup>


<br />

### Other frequently asked questions

<Accordion title="How much does it cost?">
    We have a free-forever tier, but if you require advanced features and high volume usage you can leverage our credit-usage model. Simply purchase credits within your <a href="https://dash.mixpeek.com">dashboard</a> and as you use the API (uploads and search) your credit count will diminish. You will receive warnings as your credit consumption reduces to zero. Once it does, you'll default to free-tier features. This will not impact your Mixpeek API.

    Check out the <a href="https://mixpeek.com/pricing">Pricing Page</a> for details

</Accordion>

<Accordion title="How does Mixpeek compare to alternatives?">
    As a developer, you have two options:
        1. Train your vector embedding models on specific filetypes (i.e. <a href="https://github.com/openai/CLIP">CLIP</a> for images, <a href="https://github.com/openai/whisper">Whisper</a> for audio, etc.)
        2. Extract the contents of each of these file types into a standard output: text

    Mixpeek is the only object-store agnostic, multi-modal API that grants NLP-like Q&A to users without having to manage any ML, data wranging, etc.

</Accordion>

<Accordion title="How secure is Mixpeek?">
  See our <a href="https://mixpeek.com/security">Security Page</a>.
</Accordion>

<Accordion title="What is the vision for Mixpeek?">
  Multimodal understanding
</Accordion>

<Warning>
  Note: Any questions we didn't answer? Send us an email: info@mixpeek.com
</Warning>
