---
title: "FAQ"
description: "Frequently asked questions"
icon: "question"
iconType: "solid"
---

## FAQ

### What file types does Mixpeek support?

<CardGroup cols={2}>
  <Card
    title="Image"
    icon="file-image"
  >
    <ul>
      <li>PNG, JPG, JPEG</li>
      <li>GIF, SVG, WEBP</li>
      <li>TIFF, BMP</li>
    </ul>
  </Card>

  <Card
    title="Video"
    icon="file-video"
  >
    <ul>
      <li>MP4, AVI, MOV</li>
      <li>WMV, FLV, MKV</li>
      <li>WEBM, M4V</li>
    </ul>
  </Card>
</CardGroup>

<br />

### Other frequently asked questions

<Accordion title="How much does it cost?">
    We have a free-forever tier, but if you require advanced features and high volume usage you can leverage our credit-usage model. Simply purchase credits within your <a href="https://dash.mixpeek.com">dashboard</a> and as you use the API your credit count will diminish. You will receive warnings as your credit consumption reduces to zero. Once it does, you'll default to free-tier features. This will not impact your Mixpeek API.

    Check out the <a href="https://mixpeek.com/pricing">Pricing Page</a> for details

</Accordion>

<Accordion title="How does Mixpeek compare to alternatives?">
    As a developer, you have two options:
        1. Train your vector embedding models on specific filetypes (i.e. <a href="https://github.com/openai/CLIP">CLIP</a> for images, <a href="https://github.com/openai/whisper">Whisper</a> for audio, etc.)
        2. Extract the contents of each of these file types into a standard output: text

    Mixpeek is the only object-store agnostic, multi-modal API that grants NLP-like Q&A to users without having to manage any ML, data wranging, etc.

</Accordion>

<Accordion title="How secure is Mixpeek?">
  See our <a href="https://mixpeek.com/security">Security Page</a>.
</Accordion>

<Accordion title="What is the vision for Mixpeek?">
  Multimodal understanding
</Accordion>

<Warning>
  Note: Any questions we didn't answer? Send us an email: info@mixpeek.com
</Warning>
