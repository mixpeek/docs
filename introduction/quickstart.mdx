---
title: "Quickstart"
icon: "rocket"
iconType: "solid"
---

# Mixpeek Quickstart Guide

<Note>
  There is an interactive version of this guide embedded in your dashboard on
  the <a href="https://dash.mixpeek.com/notebooks">Notebooks page</a>
</Note>

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/jkIXzfKBvM0"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

## Getting Started

First, install the required libraries:

`pip install requests`

```python
import requests
import json
import time

# Replace with your Mixpeek API key
API_KEY = "YOUR_API_KEY"
BASE_URL = "https://api.mixpeek.com"

headers = {
    'Authorization': f'Bearer {API_KEY}',
    'Content-Type': 'application/json'
}
```

## Indexing and Retrieving Video Data

### Step 1: Index and Perform Feature Extraction

Start by indexing a video URL:

```python
url = f"{BASE_URL}/index/videos/url"

payload = json.dumps({
    "url": "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/starter/aussie_agility.mp4",
    "collection_id": "quickstart",
    "metadata": {
        "hello": "world"
    }
    "video_settings": [{
        "interval_sec": 10,
        "read": {"model_id": "video-descriptor-v1"},
        "embed": {"model_id": "multimodal-v1"},
        "transcribe": {"model_id": "polyglot-v1"},
        "describe": {
            "model_id": "video-descriptor-v1",
            "prompt": "Create a holistic description of the video, include sounds and screenplay"
        },
        "json_output": {
            "response_shape": {"emotions": ["str"]},
            "prompt": "This is a list of emotion labels, each one should be a string representing the scene."
        }
    }]
})

response = requests.post(url, headers=headers, data=payload)
task_id = response.json()['task_id']
print(f"Indexing started. Task ID: {task_id}")
```

### Step 2: Wait for Task Completion

Wait for the indexing task to complete:

```python
def check_task_status(task_id):
    url = f"{BASE_URL}/tasks/{task_id}"
    response = requests.get(url, headers=headers)
    return response.json()['status']

while True:
    status = check_task_status(task_id)
    print(f"Current task status: {status}")
    if status == 'DONE':
        break
    time.sleep(2)

asset_id = response.json()['asset_id']
```

### Step 3: Retrieve Full File Properties

Once the indexing is complete, retrieve the fully extracted video data:

```python
url = f"{BASE_URL}/assets/{asset_id}/features"

response = requests.get(url, headers=headers)
asset_data = response.json()
print(json.dumps(asset_data, indent=2))
```

```json
{
  "asset": {
    "asset_id": "c2ea4838-f6bd-4bc5-892b-a98e22c3b8fd",
    "collection_id": "quickstart",
    "status": "DONE",
    "url": "video.mp4",
    "modality": "video"
  },
  "features": {
    "video": [
      {
        "start_time": 0.0,
        "end_time": 5.0,
        "interval_sec": 60,
        "modality": "video",
        "created_at": "2024-11-08T16:56:01.330858Z"
      }
    ],
    "image": [],
    "text": [],
    "audio": []
  }
}
```

## Searching Indexed Content

With your video indexed, you can now perform text-based searches across your collection:

```python
url = f"{BASE_URL}/features/search/text"

payload = json.dumps({
    "query": "dog jumping",
    "collection_ids": ["quickstart"],
    "filters": {
        "AND": [
            {
                "key": "metadata.hello",
                "value": "world",
                "operator": "eq"
            }
        ]
    },
    "search_type": "semantic"
})

response = requests.post(url, headers=headers, data=payload)
search_results = response.json()
print(json.dumps(search_results, indent=2))
```

## Next Steps

- Explore more advanced indexing options in the [API documentation](/api-documentation)
- Learn about [file storage integrations](/integrations) for various cloud providers
- Discover [exciting use cases](/use-cases) like Real-Time Video Alerting and Visual Discovery
