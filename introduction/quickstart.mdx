---
title: "Quickstart"
icon: "truck-fast"
iconType: "solid"
---

## What is Mixpeek?

Your software likely stores unstructured and structured data across various datatypes: `documents`, `images`, `video` and `audio` not the least of which is `text`.

Unstructured data tends to live in an object store like Amazon S3, Azure Blob Store or Google Cloud Storage. Then structured in your database like Postgres or MongoDB.

Mixpeek allows you treat both your object store and transactional database as a single entity.

## How does it work?

Mixpeek is a multimodal pipeline development kit, which put simply is a chain of user-defined tasks that are applied to your objects as they're added to your own storage, processed then sent to your transactional database.

This allows you to structure your unstructured data using custom, powerful logic in real-time.

![mixpeek diagram](https://mixpeek.com/static/img/diagrams/high-level.png)

### A Simple Example

Say you upload an image: `dog.png` to your S3 bucket and you want to extract the tags and create an embedding of the image itself.

You'd create a Mixpeek pipeline that combines ML models and gets invoked whenever there's a new object in your bucket.

## Your first pipeline

Here's an example pipeline that creates an embedding and tags.

```python
def function(event, context):
  mixpeek = Mixpeek("API_KEY")

  # create an embedding
  embedding = mixpeek.embed.image(model_id="openai/clip-vit-base-patch32")
  # create tags
  tags = mixpeek.extract.text(model_id="microsoft/conditional-detr-resnet-50")

  return {
    "file_url": event.object_url,
    "tags": tags,
    "embedding": embedding
}
```

[Create pipeline documentation](/pipelines/create)

Once we create this pipeline then connect our S3 bucket and finally MongoDB collection then enable it.

## Your first connection

<Tip>
  Every new account comes with a preconfigured S3 and MongoDB connection so you
  can get started right away. Alternatively, you bring your own.
</Tip>

![default connections](/images/default-connections.png)

[Create connection documentation](/connections/create)

## Setup pipelines

#### Two options for pipeline creation

<CardGroup cols={2}>

<Card 
title="Github for CI/CD" 
icon="github" 
iconType="duotone" 
color="#ca8b04"
href="/pipelines/github"
>
  Integrate a private Github repository directly. We'll update the pipeline everytime you commit.

</Card>

<Card title="API Post Directly" icon="code" iconType="duotone" color="#ca8b04" href="/pipelines/create">
  Create and configure your pipeline by sending the pipeline as a string.

</Card>
</CardGroup>

Previously, we would have created an AWS IAM role, which opens up a listener on your S3 bucket `dogs`, every new object gets sent through the pipeline-as-code we defined above and then sent into our MongoDB collection: `dog_objects` (which was also instantiated previously).

That's really it! Mixpeek is designed to be "set and forget", never think about processing your S3 bucket again.

#### Sample output

Here's an example output from the S3 object: `dog.png` that gets sent into your MongoDB collection:

```json
{
  "object_url": "s3://dog.png",
  "text": "australian shepherd",
  "tags": ["dog", "shepherd"],
  "embedding": [0, 1, 2, 3],
  "metadata": {
    "pipeline_version": "v1"
  }
}
```

## Use the Methods directly

You can also use the `extract`, `embed` and `generate` methods outside of a pipeline.

```python
from mixpeek import Mixpeek

mixpeek = Mixpeek("API_KEY")

output = mixpeek.embed.text(
  input="lorem ipsum",
  model_id="mixedbread-ai/mxbai-embed-large-v1"
)
```

<Note>
  To use the API, you need to [register an API key](https://mixpeek.com/start)
  and an engineer will contact you.
</Note>

## What does it enable?

Since you'll have fresh vectors, metadata and extracted contents you can design hyper-targeted queries that span all your use cases:

- RAG (Retrieval Augmented Generation)
- Recommendation Systems
- Hybrid Search Engines

All without having to think about data prep again. You can even modify your pipeline, and the new version will be appended to the `metadata.pipeline_version` key, so you can filter your pipeline code changes against the output data.
