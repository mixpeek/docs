---
title: "Taxonomies"
description: "Enrich documents with similarity-based joins"
---

Taxonomies let you attach structured metadata to documents by matching them against a reference collection. They are implemented as retriever-powered joins and can run on demand or be materialized into collections.

## Taxonomy Types

| Type | Structure | When to Use |
|------|-----------|-------------|
| Flat | Single-level reference collection | Face enrollment, entity linking, simple lookups |
| Hierarchical | Parent/child nodes with inheritance | Org charts, product categories, multi-level labeling |

Each node references a collection, retriever, and list of enrichment fields. Child nodes inherit parent properties automatically.

### Flat Taxonomy: Product Catalog Recognition

```mermaid
graph LR
    subgraph "Multimodal Documents"
        D1[Video Frame<br/>CLIP Embedding<br/>Timestamp: 00:15]
        D2[Product Image<br/>CLIP Embedding<br/>Source: Instagram]
        D3[Audio Transcript<br/>Text Embedding<br/>'red running shoes']
        D4[User Upload<br/>CLIP Embedding<br/>Query photo]
    end
    
    subgraph "Product Catalog Reference"
        P1[Nike Air Zoom<br/>SKU: NK-2024-RED<br/>Category: Athletic<br/>Price: $129.99]
        P2[Adidas Ultraboost<br/>SKU: AD-2024-BLK<br/>Category: Running<br/>Price: $180.00]
        P3[New Balance 990<br/>SKU: NB-2024-GRY<br/>Category: Lifestyle<br/>Price: $199.99]
    end
    
    D1 -->|Visual Match<br/>Score: 0.92| P1
    D2 -->|Visual Match<br/>Score: 0.89| P2
    D3 -->|Semantic Match<br/>Score: 0.87| P1
    D4 -->|Visual Match<br/>Score: 0.91| P3
```

In a flat taxonomy, documents from any modality (video, image, audio, text) are matched against a single reference collection. Each document uses its appropriate feature embedding (CLIP for visual, text embeddings for audio transcripts) to find the best match. Enrichment fields (SKU, category, price) are attached when similarity exceeds the threshold.

### Hierarchical Taxonomy: Media Content Classification

```mermaid
graph TD
    Root[Level 1: Brand<br/>Nike<br/>CLIP Logo Detection]
    
    Root --> L2_1[Level 2: Category<br/>Athletic Performance<br/>Scene Classification]
    Root --> L2_2[Level 2: Category<br/>Lifestyle Fashion<br/>Scene Classification]
    
    L2_1 --> L3_1[Level 3: Sport Type<br/>Running<br/>Activity Detection]
    L2_1 --> L3_2[Level 3: Sport Type<br/>Training<br/>Activity Detection]
    
    L2_2 --> L3_3[Level 3: Style<br/>Streetwear<br/>Context Analysis]
    L2_2 --> L3_4[Level 3: Style<br/>Sneaker Culture<br/>Context Analysis]
    
    L3_1 --> L4_1[Level 4: Audience<br/>Recreational Runners<br/>Demographic Model]
    L3_1 --> L4_2[Level 4: Audience<br/>Competitive Athletes<br/>Demographic Model]
    
    L3_2 --> L4_3[Level 4: Audience<br/>Gym Members<br/>Demographic Model]
    
    L3_3 --> L4_4[Level 4: Audience<br/>Gen Z Fashion<br/>Demographic Model]
    
    L3_4 --> L4_5[Level 4: Audience<br/>Sneaker Collectors<br/>Demographic Model]
    
    L4_1 --> L5_1[Level 5: Campaign<br/>Run Club 2024<br/>NK-RC-2024<br/>30s Video]
    L4_1 --> L5_2[Level 5: Campaign<br/>5K Challenge<br/>NK-5K-2024<br/>15s Video]
    
    L4_2 --> L5_3[Level 5: Campaign<br/>Marathon Pro<br/>NK-MP-2024<br/>60s Video]
    
    L4_3 --> L5_4[Level 5: Campaign<br/>Training Club<br/>NK-TC-2024<br/>45s Video]
    
    L4_4 --> L5_5[Level 5: Campaign<br/>Urban Style<br/>NK-US-2024<br/>Image Set]
    
    L4_5 --> L5_6[Level 5: Campaign<br/>Air Max Day<br/>NK-AM-2024<br/>90s Video]
    
    D1[Video: Marathon Race] -.->|Matched| L5_3
    D2[Social: Street Photo] -.->|Matched| L5_5
```

In a hierarchical taxonomy, documents traverse multiple levels of progressive refinement. Starting from a broad brand classification (1 node), through content category (2 nodes), sport/style type (4 nodes), audience segmentation (5 nodes), to specific campaigns (6 nodes). Each level narrows the classification using different multimodal features—CLIP for brand detection, scene classification for categories, activity detection for sport types, demographic models for audiences, and campaign-specific patterns at the final level. Documents inherit all properties from parent nodes as they traverse down the tree.

## Execution Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `on_demand` | Enrich documents at query time inside a retriever (`taxonomy@v1` stage) | Exploratory workflows, testing, dynamic reference data |
| `materialize` | Batch enrichment after extraction; results persisted in the collection | Production search, low-latency retrieval, analytics |

Configure execution mode via a collection’s `taxonomy_applications` array or by adding a taxonomy stage to a retriever.

## Internals: JOIN Stage

Taxonomies reuse the `join@v1` stage under the hood:

- **Direct join** – key-based match (`join_type: "direct"`).
- **Retriever join** – similarity match using a nested retriever (`join_type: "retriever"`).
- **Join strategies** – `replace`, `enrich`, `left`, or `append` control how fields merge.

Parallel execution (`asyncio.gather`) makes retrieval joins 10–50× faster than sequential lookups.

## Create a Flat Taxonomy

```bash
curl -sS -X POST "$MP_API_URL/v1/taxonomies" \
  -H "Authorization: Bearer $MP_API_KEY" \
  -H "X-Namespace: $MP_NAMESPACE" \
  -H "Content-Type: application/json" \
  -d '{
    "taxonomy_name": "employee_faces",
    "taxonomy_type": "flat",
    "retriever_id": "ret_face_matcher",
    "input_mappings": {
      "query_embedding": "mixpeek://face_detector@v2/face_embedding"
    },
    "source_collection": {
      "collection_id": "col_employee_embeddings",
      "enrichment_fields": [
        { "field_path": "metadata.name", "merge_mode": "enrich" },
        { "field_path": "metadata.department", "merge_mode": "enrich" }
      ]
    }
  }'
```

## Create a Hierarchical Taxonomy

```bash
curl -sS -X POST "$MP_API_URL/v1/taxonomies" \
  -H "Authorization: Bearer $MP_API_KEY" \
  -H "X-Namespace: $MP_NAMESPACE" \
  -H "Content-Type: application/json" \
  -d '{
    "taxonomy_name": "org_roles",
    "taxonomy_type": "hierarchical",
    "retriever_id": "ret_face_matcher",
    "input_mappings": {
      "query_embedding": "mixpeek://face_detector@v2/face_embedding"
    },
    "hierarchy": [
      {
        "node_id": "employees",
        "collection_id": "col_employee_embeddings",
        "enrichment_fields": ["metadata.employee_id", "metadata.department"]
      },
      {
        "node_id": "executives",
        "collection_id": "col_executives",
        "retriever_id": "ret_executive_face",
        "parent_node_id": "employees",
        "enrichment_fields": ["metadata.executive_level", "metadata.budget_authority"]
      }
    ]
  }'
```

Hierarchical nodes inherit parent enrichment properties; children can override or extend them.

## Attach to a Collection

```json
{
  "taxonomy_applications": [
    {
      "taxonomy_id": "tax_employee_faces",
      "execution_mode": "materialize"
    },
    {
      "taxonomy_id": "tax_org_roles",
      "execution_mode": "on_demand"
    }
  ]
}
```

- Materialized enrichment updates documents ~30 seconds after ingestion completes (debounced to avoid thrashing).
- On-demand enrichment keeps documents untouched; retrievers call the taxonomy join at query time.

## Test On Demand

```bash
curl -sS -X POST "$MP_API_URL/v1/taxonomies/<taxonomy_id>/enrich" \
  -H "Authorization: Bearer $MP_API_KEY" \
  -H "X-Namespace: $MP_NAMESPACE" \
  -H "Content-Type: application/json" \
  -d '{
    "source_documents": [
      {
        "document_id": "doc_scene_123",
        "mixpeek://face_detector@v2/face_embedding": [0.12, 0.34, ...]
      }
    ],
    "mode": "on_demand"
  }'
```

## Inference Strategies

- **Manual** – Define nodes explicitly (IDs, collections, retrievers).
- **Schema-based** – Infer nodes from existing collection schemas (planned).
- **Cluster-based** – Create nodes from clustering output.
- **LLM-based** – Generate hierarchical structure from sample documents.

Combining strategies is encouraged: bootstrap via inference, then fine-tune manually.

## Monitoring

- List taxonomies: `POST /v1/taxonomies/list`
- Inspect hierarchy and node metadata: `GET /v1/taxonomies/{id}?expand_nodes=true`
- Track materialized enrichment progress via webhook events (`collection.documents.written`)
- Use retriever analytics to ensure taxonomy stages don’t dominate latency.

## Best Practices

1. **Start flat** for quick wins; layer hierarchies once value is proven.
2. **Keep enrichment minimal**—copy only fields needed at query time.
3. **Cache taxonomy stages** in retrievers when reference collections rarely change.
4. **Version taxonomies** (via snapshots) before major structural changes.
5. **Combine with clusters** to discover candidate nodes and measure coverage.

Taxonomies let you inject domain knowledge into multimodal search—link documents to canonical entities without relying on brittle key joins.
