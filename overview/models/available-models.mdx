---
title: "Available Models"
description: "Overview of embedding model options from simple to advanced"
---

Mixpeek offers three tiers of embedding model implementations, ranging from simplified multimodal options to custom enterprise solutions.

## 1. Simplified Multimodal Models

These models provide an easy-to-use interface for common modalities. Mixpeek automatically selects and updates the most performant models based on industry benchmarks.

| Modality | Model ID | Vector Size | Benchmarks | Description |
|----------|----------|-------------|------------|-------------|
| Text | `text` | 1024 | [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) | General purpose text embedding |
| Image | `image` | 512 | [ImageNet](https://www.image-net.org/) | Visual feature extraction |
| Multimodal | `multimodal` | 1024 | [ActivityNet](http://activity-net.org/) | Temporal video understanding |
| Audio | `audio` | 768 | [SUPERB](https://superbbenchmark.github.io) | Audio feature extraction |
| Keyword | `keyword` | Sparse | - | Sparse text embeddings |

Example usage:
```python
{
    "type": "text",
    "value": "search query",
    "embedding_model": "text"  # Uses the default model
}
```

## 2. Hosted Model Selection

For more control, you can specify exact model implementations:

| Model ID | Modalities | Vector Size | Type | Provider |
|----------|------------|-------------|------|----------|
| `baai-bge-m3` | Text | 1024 | Dense | BAAI |
| `openai-clip-vit-base-patch32` | Image, Text | 512 | Dense | OpenAI |
| `naver-splade-v3` | Text | Sparse | Sparse | Naver |
| `vertex-multimodal` | Image, Video, Text | 1408 | Dense | Google |

Example usage:
```python
{
    "type": "text",
    "value": "search query",
    "embedding_model": "baai-bge-m3"  # Specific model selection
}
```

<Tip>Email us for help deciding which model is best for your use case at no cost: info@mixpeek.com</Tip>

## 3. Custom Model Integration



Enterprise customers can integrate their own models:

1. Deploy your model with a compatible API
2. Register the model in your namespace
3. Use your custom model ID in requests

Example configuration:
```python
{
    "namespace_id": "enterprise-ns",
    "model_config": {
        "id": "custom-model-v1",
        "endpoint": "https://your-model-endpoint",
        "supported_modalities": ["text", "image"],
        "vector_size": 768
    }
}
```

Example usage:
```python
# X-Namespace Header: enterprise-ns
{
    "type": "text",
    "value": "search query",
    "embedding_model": "custom-model-v1",
}
```

<Note>
  Enterprise Feature: Requires namespace configuration, email us for more info: info@mixpeek.com
</Note>

## Model Registry Details

Each model in the registry includes:
- Supported modalities
- Vector type (dense or sparse)
- Output dimensions
- Hosting location and provider
- Performance metrics