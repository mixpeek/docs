---
title: "Quickstart"
description: "Get up and running with Mixpeek in minutes"
---

<Note>
  This quickstart guide will walk you through creating a simple multimodal search application with Mixpeek. You'll learn how to ingest content, extract features, and build a search endpoint.
</Note>

[Watch an Intro Video](/studio/quickstart)

## Prerequisites

Before you begin, make sure you have:

- A Mixpeek account (sign up at [mixpeek.com/start](https://mixpeek.com/start))
- Your API key (found in your dashboard)
- Basic familiarity with REST APIs

## Complete Example

```python
from mixpeek import Mixpeek
import time

# Initialize the Mixpeek client
mp = Mixpeek(api_key="YOUR_API_KEY")

# Create a namespace
namespace = mp.namespaces.create(
    name="quickstart",
    description="My first Mixpeek project"
)
namespace_id = namespace["namespace_id"]

# Create a bucket
bucket = mp.buckets.create(
    namespace_id=namespace_id,
    name="content-bucket",
    description="Storage for our content",
    schema={
      "my_img": {
        "type" : "image"
      }
    }
)
bucket_id = bucket["bucket_id"]

# Create a collection
collection = mp.collections.create(
    namespace_id=namespace_id,
    name="content-collection",
    description="Processed content documents",
    source={
      "bucket": bucket_id
    }
    feature_extractors=[
      {"feature_extractor_name": "scene_splitter"}
    ]
)
collection_id = collection["collection_id"]

# Upload an object
object = mp.objects.create(
    bucket_id=bucket_id,
    name="content-bucket",
    files=[
        {
            "my_img": "https://example.com/sample-image.jpg"
        }
    ]
)
object_id = object["object_id"]

# Wait for processing to complete
print("Processing content, please wait...")
time.sleep(30)  # Adjust based on content size

# Create a retriever
retriever = mp.retrievers.create(
    namespace_id=namespace_id,
    name="content-retriever",
    description="Search across processed content",
    stages=[
        {
            "name": "embedding_search",
            "type": "vector",
            "collection_id": collection_id,
            "index": "multimodal",
            "limit": 20
        }
    ]
)
retriever_id = retriever["retriever_id"]

# Search for content
results = mp.retrievers.execute(
    retriever_id=retriever_id,
    query={
        "text": "show me images with people"
    }
)

# Display results
print("\nSearch Results:")
for result in results["results"]:
    print(f"Document ID: {result['document_id']}")
    print(f"Score: {result['score']}")
    print(f"Content: {result['content']}")
    print("---")
```

## Next Steps

Congratulations! You've just built a simple multimodal search application with Mixpeek. To continue your journey:

<CardGroup cols={3}>
  <Card title="Learn about Namespaces" icon="folder-tree" href="/management/namespaces">
    Organize your data into isolated environments
  </Card>
  
  <Card title="Explore Feature Extractors" icon="microchip" href="/management/features">
    Discover advanced extraction capabilities
  </Card>

  <Card title="Build Powerful Retrievers" icon="magnifying-glass" href="/retrieval/overview">
    Create sophisticated search experiences
  </Card>
</CardGroup> 