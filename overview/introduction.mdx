---
title: "Introduction"
description: "Learn how Mixpeek enables powerful multimodal search applications across different types of media"
---

<Note>
  Mixpeek is a developer platform for building multimodal search applications that understand user intention across multiple types of media.
</Note>

<CardGroup cols={2}>
  <Card title="Extract Features" icon="wand-magic-sparkles">
    Extract meaningful features from images, videos, and text automatically
  </Card>
  
  <Card title="Build Search" icon="magnifying-glass">
    Create powerful search experiences across different content types
  </Card>

  <Card title="Customize" icon="sliders">
    Build custom search experiences tailored to your specific use case
  </Card>

  <Card title="Scale" icon="rocket">
    Deploy production-ready applications with scalable infrastructure
  </Card>
</CardGroup>

## How It Works

<Steps>
  <Step title="Index Your Content">
    Upload your media (images, videos, text) to Mixpeek
  </Step>
  <Step title="Extract Features">
    Mixpeek automatically processes your content to extract meaningful features
  </Step>
  <Step title="Search & Analyze">
    Use our APIs to build search, recommendation, and analytics applications
  </Step>
</Steps>

## Key Features

<AccordionGroup>
  <Accordion title="🔍 Multimodal Search" icon="magnifying-glass">
    Build sophisticated search experiences:
    - Natural language queries across all media types
    - Visual similarity search for images and videos
    - Cross-modal search (find images with text, or vice versa)
    - Semantic understanding of content

    Learn more in our [Search API](/api-reference/features/search-features).
  </Accordion>

  <Accordion title="🎯 Feature Extraction" icon="gears">
    Extract valuable insights automatically:
    - Object and scene detection
    - Text extraction from images and videos
    - Face detection and recognition
    - Custom extraction pipelines

    Explore our [Features API](/concepts/features) to learn more.
  </Accordion>
</AccordionGroup>

## Common Use Cases

<CardGroup cols={2}>
  <Card title="Video Alerting" icon="video">
    Real-time monitoring and detection of objects, events, or anomalies in video streams
  </Card>
  
  <Card title="Visual Discovery" icon="image">
    Power visual search engines and recommendation systems
  </Card>

  <Card title="Multimodal Search" icon="search">
    Enable natural language search across all content types
  </Card>

  <Card title="Content Recommendation" icon="rectangle-list">
    Build personalized recommendation systems
  </Card>

  <Card title="Media Analytics" icon="chart-line">
    Gain insights through automated content analysis
  </Card>

  <Card title="Multimodal RAG" icon="robot">
    Create AI applications that process cross-modal information
  </Card>
</CardGroup>

## Getting Started

<CardGroup cols={2}>
  <Card title="Quickstart Guide" icon="play">
    Set up your first Mixpeek application
    <Link href="/overview/quickstart">Get Started →</Link>
  </Card>
  
  <Card title="Client Libraries" icon="code">
    Integrate using our SDKs
    <Link href="/overview/client-libraries">View SDKs →</Link>
  </Card>

  <Card title="API Reference" icon="book">
    Explore our REST API
    <Link href="/api-reference">View API →</Link>
  </Card>

  <Card title="Studio" icon="desktop">
    Use our visual interface
    <Link href="/studio/overview">Open Studio →</Link>
  </Card>
</CardGroup>

<Note>
  Ready to build? [Create your account](https://mixpeek.com/start) or check out our [Quickstart Guide](/overview/quickstart).
</Note>
