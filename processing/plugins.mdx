---
title: "Custom Plugins"
description: "Build and deploy custom feature extractors on Mixpeek infrastructure"
---

## Overview

Custom plugins let you run your own feature extraction logic on Mixpeek's infrastructure. You write the processing code - we handle batching, scaling, and GPU allocation.

**Two deployment modes:**
- **Batch processing** (all accounts): Process files in collections
- **Realtime inference** (Enterprise): HTTP endpoint for live requests

---

## Quick Start

### 1. Create Your Plugin

```
my_extractor/
├── manifest.py      # Schemas + metadata
├── pipeline.py      # Batch processing
├── realtime.py      # HTTP endpoint (optional, Enterprise)
└── processors/
    └── core.py      # Your logic
```

### 2. Upload to Mixpeek

```bash
# Step 1: Get presigned URL
curl -X POST "https://api.mixpeek.com/v1/namespaces/{namespace_id}/plugins/uploads" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{"name": "my_extractor", "version": "1.0.0"}'

# Step 2: Upload your zip
curl -X PUT "$PRESIGNED_URL" \
  -H "Content-Type: application/zip" \
  --data-binary @my_extractor.zip

# Step 3: Confirm upload
curl -X POST "https://api.mixpeek.com/v1/namespaces/{namespace_id}/plugins/uploads/{upload_id}/confirm" \
  -H "Authorization: Bearer $API_KEY"
```

### 3. Use in Collections

```python
client.collections.create(
    collection_name="my_collection",
    source={"type": "bucket", "bucket_ids": ["bkt_..."]},
    feature_extractor={
        "feature_extractor_name": "my_extractor",
        "version": "1.0.0",
        "parameters": {"threshold": 0.7}
    }
)
```

---

## Plugin Files

### manifest.py

Defines inputs, outputs, and parameters:

```python
from pydantic import BaseModel, Field
from typing import List

class MyInput(BaseModel):
    text: str = Field(..., description="Input text")

class MyOutput(BaseModel):
    embedding: List[float] = Field(..., description="384-dim embedding")
    label: str

class MyParams(BaseModel):
    threshold: float = Field(default=0.5, ge=0, le=1)

metadata = {
    "feature_extractor_name": "my_extractor",
    "version": "1.0.0",
    "description": "My custom extractor",
    "category": "text",
}

input_schema = MyInput
output_schema = MyOutput
parameter_schema = MyParams
supported_input_types = ["text"]

features = [
    {
        "feature_name": "my_embedding",
        "feature_type": "embedding",
        "embedding_dim": 384,
        "distance_metric": "cosine",
    },
]
```

### processors/core.py

Your processing logic:

```python
from dataclasses import dataclass
import pandas as pd

@dataclass
class MyConfig:
    threshold: float = 0.5

class MyProcessor:
    def __init__(self, config: MyConfig, progress_actor=None):
        self.config = config
        self._model = None

    def _load_model(self):
        if self._model is None:
            from sentence_transformers import SentenceTransformer
            self._model = SentenceTransformer("all-MiniLM-L6-v2")

    def __call__(self, batch: pd.DataFrame) -> pd.DataFrame:
        self._load_model()
        texts = batch["text"].fillna("").tolist()
        embeddings = self._model.encode(texts).tolist()
        batch["my_embedding"] = embeddings
        return batch
```

### pipeline.py

Wire your processor into the pipeline:

```python
from engine.plugins.extractors.pipeline import (
    PipelineDefinition, ResourceType, RowCondition, StepDefinition, build_pipeline_steps
)
from .manifest import MyParams, metadata
from .processors.core import MyConfig, MyProcessor

def build_steps(extractor_request, **kwargs):
    params = MyParams(**(extractor_request.extractor_config.parameters or {}))

    steps = [
        StepDefinition(
            service_class=MyProcessor,
            resource_type=ResourceType.CPU,
            config=MyConfig(threshold=params.threshold),
            condition=RowCondition.IS_TEXT,
        ),
    ]

    pipeline = PipelineDefinition(
        name=metadata["feature_extractor_name"],
        version=metadata["version"],
        steps=steps
    )
    return {"steps": build_pipeline_steps(pipeline)}
```

### realtime.py (Enterprise Only)

For HTTP inference endpoint:

```python
class RealtimeHandler:
    def __init__(self):
        self._model = None

    def predict(self, request: dict) -> dict:
        if self._model is None:
            from sentence_transformers import SentenceTransformer
            self._model = SentenceTransformer("all-MiniLM-L6-v2")

        text = request.get("text", "")
        embedding = self._model.encode([text])[0].tolist()
        return {"embedding": embedding}
```

---

## Using Built-in Models

Compose existing Mixpeek services instead of writing from scratch:

```python
# Option 1: Direct import
from engine.inference.intfloat.multilingual_e5_large_instruct.services import E5TextEmbeddingBatch

# Option 2: Unified registry (recommended)
from shared.inference.registry import get_batch_service
E5Batch = get_batch_service("intfloat/multilingual-e5-large-instruct")
```

**Example: Audio transcription + embedding pipeline**

```python
from shared.inference.registry import get_batch_service

WhisperBatch = get_batch_service("openai/whisper-large-v3-turbo")
E5Batch = get_batch_service("intfloat/multilingual-e5-large-instruct")

def build_steps(extractor_request, **kwargs):
    steps = [
        StepDefinition(
            service_class=WhisperBatch,
            resource_type=ResourceType.API,
            config=WhisperConfig(output_column_name="transcription"),
            condition=RowCondition.IS_AUDIO,
        ),
        StepDefinition(
            service_class=E5Batch,
            resource_type=ResourceType.CPU,
            config=E5Config(text_column="transcription"),
        ),
    ]
    return {"steps": build_pipeline_steps(PipelineDefinition(name="transcribe", version="v1", steps=steps))}
```

**Available services:**

| Service ID | Category | Use Case |
|------------|----------|----------|
| `intfloat/multilingual-e5-large-instruct` | Embedding | Text embeddings (1024 dims) |
| `google/siglip-base-patch16-224` | Embedding | Image embeddings |
| `openai/whisper-large-v3-turbo` | Transcription | Audio to text |
| `BAAI/bge-reranker-v2-m3` | Reranking | Result reordering |
| `jinaai/jina-embeddings-v2-base-code` | Embedding | Code embeddings |

---

## Deployment Lifecycle

### Deploy (Enterprise)

```bash
curl -X POST "https://api.mixpeek.com/v1/namespaces/{namespace_id}/plugins/{plugin_id}/deploy" \
  -H "Authorization: Bearer $API_KEY"
```

### Check Status

```bash
curl "https://api.mixpeek.com/v1/namespaces/{namespace_id}/plugins/{plugin_id}/status" \
  -H "Authorization: Bearer $API_KEY"
```

**Status values:**

| Status | Description |
|--------|-------------|
| `QUEUED` | Waiting in deployment queue (~30s) |
| `PENDING` | Deployment triggered |
| `IN_PROGRESS` | Blue-green rollout in progress |
| `DEPLOYED` | Ready for realtime inference |
| `FAILED` | Check `error` field for details |
| `NOT_DEPLOYED` | Batch-only mode (no realtime endpoint) |

### Undeploy

Stops the realtime endpoint but keeps the plugin:

```bash
curl -X POST "https://api.mixpeek.com/v1/namespaces/{namespace_id}/plugins/{plugin_id}/undeploy" \
  -H "Authorization: Bearer $API_KEY"
```

### Delete

Removes the plugin entirely:

```bash
curl -X DELETE "https://api.mixpeek.com/v1/namespaces/{namespace_id}/plugins/{plugin_id}" \
  -H "Authorization: Bearer $API_KEY"
```

Response includes `deployment_removed: true` if realtime endpoint was removed.

---

## Resource Types

| Type | Use For | Auto-config |
|------|---------|-------------|
| `ResourceType.CPU` | Text embeddings, classification | Batch ~64 |
| `ResourceType.GPU` | Local models (Whisper, CLIP) | Batch ~8, GPU allocation |
| `ResourceType.API` | External APIs (OpenAI, Vertex) | Concurrent requests |

## Row Conditions

Filter which rows your processor handles:

| Condition | Matches |
|-----------|---------|
| `RowCondition.IS_TEXT` | text/* MIME types |
| `RowCondition.IS_IMAGE` | image/* MIME types |
| `RowCondition.IS_VIDEO` | video/* MIME types |
| `RowCondition.IS_AUDIO` | audio/* MIME types |
| `RowCondition.IS_PDF` | application/pdf |
| `RowCondition.ALWAYS` | All rows (default) |

---

## Security Requirements

Plugins are scanned before upload confirmation. Code violating these rules is rejected.

### Allowed Imports

| Category | Libraries |
|----------|-----------|
| Data | `numpy`, `pandas`, `polars`, `pyarrow` |
| ML/AI | `torch`, `transformers`, `sentence_transformers`, `onnxruntime` |
| Image | `PIL`, `cv2`, `imageio` |
| Audio | `librosa`, `soundfile`, `ffmpeg-python` |
| HTTP | `requests`, `httpx`, `aiohttp` |
| Utils | `json`, `re`, `typing`, `dataclasses`, `pydantic`, `logging` |

### Forbidden (Security)

| Category | Blocked | Reason |
|----------|---------|--------|
| Execution | `subprocess`, `os.system`, `eval`, `exec` | Shell/code execution |
| System | `ctypes`, `socket`, `multiprocessing` | Low-level access |
| Builtins | `open`, `setattr`, `getattr`, `__import__` | File/attribute manipulation |

<Accordion title="Full list of forbidden patterns">

**Forbidden imports:**
- `subprocess`, `os.system`, `os.popen`, `os.spawn*`, `os.exec*`
- `ctypes`, `pty`, `fcntl`, `resource`
- `multiprocessing`, `threading`, `socket`
- `commands`, `popen2`

**Forbidden builtins:**
- `eval()`, `exec()`, `compile()`
- `open()`
- `__import__()`
- `globals()`, `locals()`, `vars()`
- `getattr()`, `setattr()`, `delattr()`, `hasattr()`

**Forbidden module functions:**
- `os.system`, `os.popen`, `os.spawn`, `os.exec`, `os.fork`, `os.kill`
- `importlib.import_module`
- `pickle.loads`, `pickle.load`
- `marshal.loads`, `marshal.load`

</Accordion>

### Validation Error Example

```json
{
  "success": false,
  "validation_errors": [
    {
      "file": "processors/core.py",
      "line": 15,
      "message": "Forbidden import: subprocess"
    }
  ]
}
```

---

## Feature URI

After upload, reference your plugin with:

```
mixpeek://my_extractor@1.0.0/my_embedding
```

This URI is **organization-scoped** - two orgs can have the same plugin name without collision.

---

## Namespace Isolation

Plugins are isolated per namespace:

| Layer | Isolation |
|-------|-----------|
| MongoDB | `internal_id` scoping |
| S3 | `org_id/ns_id/plugin_custom/...` |
| Ray Serve | Namespace prefix in deployment names |

---

## Troubleshooting

### Plugin validation failed

Check the `validation_errors` array in the confirm response. Common issues:
- Using `setattr()` or `getattr()` - use class attributes instead
- Importing `subprocess` - use `requests` or `httpx` for HTTP calls
- Using `open()` - use provided data loading APIs

### Deployment stuck in QUEUED

Deployments are batched every 30 seconds. Wait up to 3-4 minutes for the blue-green rollout to complete.

### Plugin not found in collection

1. Verify upload was confirmed successfully
2. Check plugin is in the correct namespace
3. Ensure `feature_extractor_name` and `version` match exactly
