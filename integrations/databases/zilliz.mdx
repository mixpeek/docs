---
title: "Zilliz"
icon: "bolt"
iconType: "solid"
---

## Video

We'll be using `vuse-generic-v1` to build a collection of 1 second interval video chunks into a 768 dimension embedding collection.

<Note>
  You'll need to create a Zilliz collection called `VideoChunk` with a vector
  field of 768 dimensions.
</Note>

### Ingest

```python
from mixpeek import Mixpeek
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

# Initialize the Mixpeek client with your API key
mixpeek = Mixpeek("YOUR_API_KEY")

# Connect to Zilliz
connections.connect(
    alias="default",
    uri="YOUR_ZILLIZ_URI",
    token="YOUR_ZILLIZ_TOKEN"
)

# Define schema for VideoChunk collection
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=768),
    FieldSchema(name="start_time", dtype=DataType.DOUBLE),
    FieldSchema(name="end_time", dtype=DataType.DOUBLE)
]
schema = CollectionSchema(fields, "VideoChunk collection")

# Create collection
collection = Collection("VideoChunk", schema)

# Process video chunks
processed_chunks = mixpeek.tools.video.process(
    video_source="https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/Jurassic+Park+(2).mp4",
    chunk_interval=1, # 1 second intervals
    resolution=[720, 1280]
)

for chunk in processed_chunks:
    print(f"Processing video chunk: {chunk['start_time']}")

    # embed each chunk
    embed_response = mixpeek.embed.video(
        model_id="vuse-generic-v1",
        input=chunk['base64_chunk'],
        input_type="base64"
    )

    # Insert into Zilliz
    collection.insert([
        [embed_response['embedding']],
        [chunk["start_time"]],
        [chunk["end_time"]]
    ])

# Create index and load collection
collection.create_index(field_name="vector", index_params={"index_type": "IVF_FLAT", "metric_type": "IP", "params": {"nlist": 1024}})
collection.load()
```

### Text Query

```python
query = "two boys inside a car"

embed_response = mixpeek.embed.video(
    model_id="vuse-generic-v1",
    input=query,
    input_type="text"
)

search_params = {
    "metric_type": "IP",
    "params": {"nprobe": 10},
}

results = collection.search(
    data=[embed_response['embedding']],
    anns_field="vector",
    param=search_params,
    limit=10,
    output_fields=["start_time", "end_time"]
)

for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, Distance: {hit.distance}, Start Time: {hit.entity.get('start_time')}, End Time: {hit.entity.get('end_time')}")
```

### Video Query

```python
# we'll use a cartoon version of jurassic park
file_url = "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/rabbit-jurassic.mp4"

embed_response = mixpeek.embed.video(
    model_id="vuse-generic-v1",
    input=file_url,
    input_type="url"
)

search_params = {
    "metric_type": "IP",
    "params": {"nprobe": 10},
}

results = collection.search(
    data=[embed_response['embedding']],
    anns_field="vector",
    param=search_params,
    limit=10,
    output_fields=["start_time", "end_time"]
)

for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, Distance: {hit.distance}, Start Time: {hit.entity.get('start_time')}, End Time: {hit.entity.get('end_time')}")
```

## Image

We'll be using `clip-v1` to build a collection of image embeddings with 512 dimensions.

<Note>
  You'll need to create a Zilliz collection called `Image` with a vector field
  of 512 dimensions.
</Note>

### Ingest

```python
from mixpeek import Mixpeek
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

# Initialize the Mixpeek client with your API key
mixpeek = Mixpeek("YOUR_API_KEY")

# Connect to Zilliz
connections.connect(
    alias="default",
    uri="YOUR_ZILLIZ_URI",
    token="YOUR_ZILLIZ_TOKEN"
)

# Define schema for Image collection
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=512),
    FieldSchema(name="image_url", dtype=DataType.VARCHAR, max_length=500)
]
schema = CollectionSchema(fields, "Image collection")

# Create collection
collection = Collection("Image", schema)

# List of image URLs to process
image_urls = [
    "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/image1.jpg",
    "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/image2.jpg",
    "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/image3.jpg",
    "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/image4.jpg"
]

for url in image_urls:
    print(f"Processing image: {url}")

    # Embed each image
    embed_response = mixpeek.embed.image(
        model_id="openai-clip-vit-base-patch32",
        input=url,
        input_type="url"
    )

    # Insert into Zilliz
    collection.insert([
        [embed_response['embedding']],
        [url]
    ])

# Create index and load collection
collection.create_index(field_name="vector", index_params={"index_type": "IVF_FLAT", "metric_type": "IP", "params": {"nlist": 1024}})
collection.load()
```

### Text Query

```python
query = "a cat sitting on a windowsill"

embed_response = mixpeek.embed.image(
    model_id="openai-clip-vit-base-patch32",
    input=query,
    input_type="text"
)

search_params = {
    "metric_type": "IP",
    "params": {"nprobe": 10},
}

results = collection.search(
    data=[embed_response['embedding']],
    anns_field="vector",
    param=search_params,
    limit=5,
    output_fields=["image_url"]
)

for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, Distance: {hit.distance}, Image URL: {hit.entity.get('image_url')}")
```

### Image Query

```python
# Use an image from the same bucket as a query
query_image = "https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/zilliz/query_image.jpg"

embed_response = mixpeek.embed.image(
    model_id="clip-v1",
    input=query_image,
    input_type="url"
)

search_params = {
    "metric_type": "IP",
    "params": {"nprobe": 10},
}

results = collection.search(
    data=[embed_response['embedding']],
    anns_field="vector",
    param=search_params,
    limit=5,
    output_fields=["image_url"]
)

for hits in results:
    for hit in hits:
        print(f"ID: {hit.id}, Distance: {hit.distance}, Image URL: {hit.entity.get('image_url')}")
```
