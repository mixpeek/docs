---
title: "Overview"
description: "ML model options for each method"
icon: "brain"
iconType: "solid"
---

When using the mixpeek methods, you provide the `model` in each request regardless of method: `extract`, `embed`, and `generate`.

For instance `mixpeek.extract()`, `mixpeek.embed()` or `mixpeek.generate()`

<CodeGroup>

```python Mock Request
mixpeek.embed("jinaai/jina-embeddings-v2-base-en")
```

```python Mock Response
{
    "embedding": [0, 1, 3, 21]
}
```

</CodeGroup>

The list below are all the embedding models currently supported in the SDK. For embed, use the dimensions to create your DB index.

<Note>
  We add models regularly, so if we're missing any
  <a href="https://mixpeek.com/contact">reach out</a>.
</Note>

## Models

### Embedding

| Name                                         | Modality    | Dimensions | URL                                                           |
| -------------------------------------------- | ----------- | ---------- | ------------------------------------------------------------- |
| `sentence-transformers/all-MiniLM-L6-v2`     | Text        | 384        | [Sentence Transformers](https://www.sbert.net/)               |
| `nomic-ai/nomic-embed-text-v1`               | Text        | 768        | [Nomic AI](https://nomic.ai/)                                 |
| `jinaai/jina-embeddings-v2-base-en`          | Text        | 768        | [Jina AI](https://jina.ai/)                                   |
| `google-bert/bert-base-multilingual-uncased` | Text        | 768        | [Google BERT](https://github.com/google-research/bert)        |
| `mixedbread-ai/mxbai-embed-large-v1`         | Text        | 1024       | [MixedBread AI](https://mixedbread.ai/)                       |
| `openai/clip-vit-base-patch32`               | Text, Image | 512        | [OpenAI Clip](https://github.com/openai/CLIP)                 |
| `mixpeek/vuse-generic-v1`                    | Text, Video | 768        | [Mixpeek](https://mixpeek.com/models/mixpeek/vuse-generic-v1) |

### Generation

| Name                         | Modality | URL                                                                            |
| ---------------------------- | -------- | ------------------------------------------------------------------------------ |
| `openai/gpt-3.5-turbo`       | Text     | [GPT-3.5 Turbo](https://beta.openai.com/docs/models/gpt-3.5-turbo)             |
| `openai/gpt-4-turbo-preview` | Text     | [GPT-4 Turbo Preview](https://beta.openai.com/docs/models/gpt-4-turbo-preview) |
| `openai/gpt-4-turbo`         | Text     | [GPT-4 Turbo](https://beta.openai.com/docs/models/gpt-4-turbo)                 |

### Extraction

<Info>Work in progress</Info>

## Fine-Tuning

<Warning>Available to Enterprise customers only</Warning>

To fine-tune any of the models (`extract`, `generate`, and `embed`), follow these steps:

<Steps>
  <Step title="Send Annotated Data">
    Send your annotated data to an S3 bucket and connect it via the
    <a href="/connections/s3">Connections</a> service. This will return a `connection_id`.
    Ensure the data is well-organized and labeled according to the model's requirements
    (we'll provide specs)
  </Step>
  <Step title="Initiate Fine-Tuning">
    Use the Mixpeek API to start a fine-tuning job. Specify the base
    `model_id`, the S3 bucket path, and `specs` that tell the fine-tuner how to run:

    ```python
    mixpeek.models.tune(
      model_id="jinaai/jina-embeddings-v2-base-en",
      annotation={
        "connection_id": "conn_123",
        "specs": "specs.json"
      }
    )
    ```

    This will return a new model_id that you can use in your pipeline, for example: `model_1askdh2390`, which you'll then use in your methods like:

    ```python
      mixpeek.embed.text(model_id="model_1askdh2390", input="hello")
    ```

  </Step>
  <Step title="Version Control">
    It's recommended to store the version_id of each model state as it is fine-tuned. 
    
    If you append a `model_version` in the metadata of the pipeline it'll automatically be added to your database so you can do query-time filtering:

    ```python
    mixpeek.pipelines.create(
      ...
      destination={
        ...
        "metadata": {
          "model_version": "model_1askdh2390"
        }
      }
    )
    ```

  </Step>
</Steps>
