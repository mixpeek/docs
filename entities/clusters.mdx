---
title: "Clusters"
description: "Discover, organize, and search multimodal features using automatic and manual clustering"
---

<Warning>
Clustering is only available for enterprise customers, email info@mixpeek.com for a demo. 
</Warning>

Clusters in Mixpeek are groups of similar features automatically discovered or manually defined. They enable efficient organization, search, and analysis of your multimodal features.

<Accordion title="Why Use Clusters?">
  - **Organization**: Automatically group
  similar content 
  - **Discovery**: Find patterns and relationships in your data
  - **Performance**: Speed up searches by limiting scope 
  - **Analysis**: Understand content distribution and patterns
</Accordion>

<AccordionGroup>
  <Accordion title="Automatic Clustering">
    Mixpeek can automatically discover clusters using: 
    - Distance-based algorithms (DBSCAN) 
    - Dimensionality reduction (UMAP) 
    - Hierarchical methods (BIRCH)
  </Accordion>
</AccordionGroup>

<Note>Need to cluster manually against business rules, domain expertise or existing hierarchies? Use [Taxonomies](/entities/taxonomies)</Note>


## How Clustering Works

<Steps>
  <Step title="Feature Extraction">
    Assets are processed into features representing: 
    - Visual content
    - Objects
    - Spoken Words 
    - Metadata
    - etc.
  </Step>

<Step title="Similarity Calculation">
  Features are compared using: 
  - Vector similarity 
  - Semantic relationships 
  - Temporal proximity
</Step>

  <Step title="Cluster Formation">
    Similar features are grouped based on: 
    - Distance thresholds 
    - Density patterns 
    - User-defined rules
  </Step>
</Steps>

## Use Cases

<CardGroup>
  <Card title="Content Organization" icon="folder-tree">
    Automatically organize video libraries by: 
    - Content type 
    - Visual similarity 
    - Semantic themes
  </Card>

<Card title="Pattern Discovery" icon="lightbulb">
  Uncover hidden patterns in your content: 
  - Common scenes 
  - Recurring themes 
  - Related sequences
</Card>

  <Card title="Search Enhancement" icon="magnifying-glass">
    Improve search efficiency through: 
    - Cluster-based filtering 
    - Contextual recommendations 
    - Similar content discovery
  </Card>

  <Card title="Quality Control" icon="shield-check">
    Monitor and maintain content quality by: 
    - Identifying outliers 
    - Detecting anomalies 
    - Validating content consistency
  </Card>
</CardGroup>

## Implementation

<Tabs>
  <Tab title="Development Setup">
    ```bash
    # Create development namespace
    POST /namespaces
    {
      "namespace": "content_clusters_dev",
      "embedding_modeles": ["text", "image", "multimodal"]
    }

    # Create collections
    POST /collections # with X-Namespace: content_clusters_dev
    {
      "collection": "sample"
    }
    ```
  </Tab>

  <Tab title="Cluster Discovery">
    ```python
    POST /entities/clusters/discover
    {
      "collections": ["sample"],
      "method": "hdbscan",
      "embedding_model": "text",
      "params": {
        "min_cluster_size": 3,
        "min_samples": 3,
        "umap_neighbors": 15
      },
      "naming": {
        "enabled": true, # if enabled, this automatically generates a name for the cluster
        "generative_model": "gpt-4o",
        "method": "centroid",
        "num_nearest": 3 # Use N nearest features from centroid to generate name
      },
      "assign": true,
      "sample_size": 1000
    }
    ```
  </Tab>

  <Tab title="List Clusters">
    ```python
    GET /entities/clusters
    {
      "clusters": [
        {
          "cluster_id": "clu_123",
          "cluster_name": "Athletic Footwear Ads",
          "centroid": [...],
          "nearest_centroids": [
            {"id": "feat_123", "distance": 0.1},
            {"id": "feat_456", "distance": 0.15},
            {"id": "feat_789", "distance": 0.2}
          ],
          "size": 45,
          "confidence": 0.95,
          "coordinates": {
            "x": -0.45,
            "y": 0.78
          }
        }
      ]
    }
    ```
  </Tab>
</Tabs>


## Internal Cluster Structure

Features store cluster assignments in a simplified array structure:

```json
{
  "entities": [
    {
      "id": "clu_123",
      "name": "Athletic Footwear Ads",
      "coordinates": {
        "x": -0.45,
        "y": 0.78
      },
      "score": 0.95
    }
  ]
}
```

## Searching with Clusters

<Tabs>
  <Tab title="Basic Cluster Search">
    ```python
    POST /features/search
    {
      "collections": ["sample"],
      "filters": {
        "AND": [
          {
            "key": "entities[].cluster",
            "operator": "eq",
            "value": "Athletic Footwear Ads" # can use cluster name
          }
        ]
      }
    }
    ```
  </Tab>

  <Tab title="Cluster ID Search">
    ```python
    POST /features/search
    {
      "collections": ["ad-creatives"],
      "filters": {
        "AND": [
          {
            "key": "entities[].cluster",
            "operator": "eq",
            "value": "clu_123" # can use cluster_id
          }
        ]
      }
    }
    ```
  </Tab>
</Tabs>

## Best Practices for Video Clustering

<Steps>
  <Step title="Preprocessing">
    - Extract features at appropriate intervals (10-15 seconds recommended)
    - Use the scene detection parameter to identify natural segment boundaries
    - Consider both visual and audio features for complete context
    - Normalize video resolution and quality for consistent processing
  </Step>

  <Step title="Model Selection">
    - Use multimodal embeddings for combined visual-semantic understanding
    - Consider any of our specialized models for specific content types (sports, ads, etc.)
    - Balance model complexity with processing requirements
    - Test different embedding combinations for optimal results
  </Step>

  <Step title="Cluster Configuration">
    - Start with conservative clustering parameters (higher min_cluster_size)
    - Adjust confidence thresholds based on content similarity requirements
    - Use appropriate sample sizes for initial cluster discovery
    - Enable automatic naming for better cluster interpretability
  </Step>

  <Step title="Performance Optimization">
    - Batch process similar video content together
    - Cache frequently accessed cluster assignments
    - Use appropriate indexing strategies for faster lookups
    - Monitor and adjust resource utilization
  </Step>
</Steps>

<Warning>
  Video clustering can be resource-intensive. Consider these limitations:
  - Maximum video duration: 4 hours
  - Maximum file size: 2GB
  - Processing timeout: 30 minutes
  - Rate limits apply to clustering requests
</Warning>

<Note>
  For optimal results, combine clustering with taxonomies when dealing with domain-specific video content. This provides both automated discovery and structured organization.
</Note>