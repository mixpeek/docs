---
title: "Feature Extraction"
description: "Configure and customize multimodal feature extraction for different content types"
---

<Note>
  Feature extractors allow you to define how content is processed and what information is extracted, with support for text, images, video, and audio content.
</Note>

## Extractor Types

<CardGroup cols={3}>
  <Card title="Text Processing" icon="font">
    - Text embedding
    - Language detection
    - Sentiment analysis
    - Named entity recognition
  </Card>
  
  <Card title="Image Analysis" icon="image">
    - Object detection
    - Scene classification
    - Face recognition
    - OCR extraction
  </Card>

  <Card title="Video Processing" icon="video">
    - Frame analysis
    - Transcription
    - Scene detection
    - Motion tracking
  </Card>
</CardGroup>

## Configuration

<CodeGroup>
  ```json Basic Extraction
  {
    "feature_extractors": [
      {
        "embed": [
          {
            "type": "text",
            "embedding_model": "default"
          }
        ]
      }
    ]
  }
  ```

  ```json Advanced Video Processing
  {
    "feature_extractors": [
      {
        "interval_sec": 15,
        "read": { "enabled": true },
        "embed": [
          {
            "type": "url",
            "embedding_model": "multimodal"
          },
          {
            "type": "text",
            "value": "describe this scene",
            "embedding_model": "text"
          }
        ],
        "transcribe": { "enabled": true },
        "describe": { "enabled": true },
        "detect": {
          "faces": {
            "confidence_threshold": 0.8,
            "enabled": true
          }
        }
      }
    ]
  }
  ```
</CodeGroup>

## Extractor Options

<AccordionGroup>
  <Accordion title="Common Settings">
    | Option | Type | Description | Default |
    |--------|------|-------------|---------|
    | `interval_sec` | number | Processing interval for videos | `10` |
    | `confidence_threshold` | number | Detection confidence threshold | `0.5` |
    | `embedding_model` | string | Target index for embeddings | `"default"` |
  </Accordion>

  <Accordion title="Processing Modules">
    | Module | Capabilities | Output |
    |--------|-------------|---------|
    | `embed` | Vector embeddings | Embeddings array |
    | `transcribe` | Speech-to-text | Text transcript |
    | `describe` | Scene description | Natural language |
    | `detect` | Object/face detection | Bounding boxes |
  </Accordion>
</AccordionGroup>

## Output Configuration

<Tabs>
  <Tab title="JSON Output">
    ```json
    {
      "json_output": {
        "response_shape": {
          "objects": ["str"],
          "scenes": ["str"],
          "faces": {
            "count": "int",
            "locations": ["array"]
          }
        }
      }
    }
    ```
  </Tab>

  <Tab title="Vector Output">
    ```json
    {
      "vector_output": {
        "format": "float32",
        "dimensions": 1024,
        "include_metadata": true
      }
    }
    ```
  </Tab>
</Tabs>

## Processing Flow

<Frame>
  ```mermaid
  graph TD
    A[Content Input] --> B[Feature Extraction]
    B --> C[Vector Embedding]
    B --> D[Metadata Generation]
    C --> E[Index Storage]
    D --> E
    style A fill:#f9f,stroke:#333
    style E fill:#9ff,stroke:#333
  ```
</Frame>

## Best Practices

<Steps>
  <Step title="Optimize Intervals">
    Choose appropriate processing intervals for video content
  </Step>
  <Step title="Configure Thresholds">
    Set confidence thresholds based on use case requirements
  </Step>
  <Step title="Select Indexes">
    Use appropriate vector indexes for different content types
  </Step>
  <Step title="Monitor Resources">
    Balance processing depth with resource utilization
  </Step>
</Steps>

## Limitations

<Warning>
  Be aware of these technical constraints:
  - Maximum video duration: 4 hours
  - Maximum file size: 2GB
  - Processing timeout: 30 minutes
  - Rate limits apply to extraction requests
</Warning>

For detailed implementation examples, see the [Feature Extraction API Reference](/api-reference/features/get-feature). 