---
title: "LLM Filter"
description: "Filter documents using LLM-based content evaluation and criteria matching"
---

<Frame>
  <img src="/assets/retrievers/llm-filter.svg" alt="LLM Filter stage showing content-based filtering with language models" />
</Frame>

The LLM Filter stage uses language models to evaluate document content against specified criteria, filtering based on semantic understanding rather than metadata fields.

<Note>
  **Stage Category**: FILTER (Reduces document set)

  **Transformation**: N documents → M documents (where M ≤ N, based on LLM evaluation)
</Note>

## When to Use

| Use Case | Description |
|----------|-------------|
| **Content quality filtering** | Remove low-quality or irrelevant content |
| **Semantic criteria** | Filter by meaning, not just keywords |
| **Complex requirements** | "Only technical documentation" |
| **Subjective evaluation** | Tone, style, or sentiment filtering |

## When NOT to Use

| Scenario | Recommended Alternative |
|----------|------------------------|
| Simple metadata filtering | `structured_filter` (faster) |
| Large result sets (100+) | Too slow, pre-filter first |
| Deterministic rules | `structured_filter` |
| Low latency requirements | Use metadata filters |

## Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `model` | string | *Required* | LLM model to use |
| `criteria` | string | *Required* | Natural language filter criteria |
| `content_field` | string | `content` | Field to evaluate |
| `explanation` | boolean | `false` | Include filtering explanation |
| `batch_size` | integer | `10` | Documents per LLM call |

## Available Models

| Model | Speed | Quality | Cost |
|-------|-------|---------|------|
| `gpt-4o-mini` | Fast | Good | Low |
| `gpt-4o` | Medium | Excellent | Medium |
| `claude-3-haiku` | Fast | Good | Low |
| `claude-3-sonnet` | Medium | Excellent | Medium |

## Configuration Examples

<CodeGroup>
```json Basic Content Filter
{
  "stage_type": "filter",
  "stage_id": "llm_filter",
  "parameters": {
    "model": "gpt-4o-mini",
    "criteria": "Keep only documents that contain technical information about software development"
  }
}
```

```json Quality Filter
{
  "stage_type": "filter",
  "stage_id": "llm_filter",
  "parameters": {
    "model": "gpt-4o-mini",
    "criteria": "Filter out documents that are: incomplete, contain mostly ads/spam, or are not in English",
    "explanation": true
  }
}
```

```json Topic Relevance
{
  "stage_type": "filter",
  "stage_id": "llm_filter",
  "parameters": {
    "model": "claude-3-haiku",
    "criteria": "Keep documents specifically about {{INPUT.topic}}. Exclude tangentially related or off-topic content."
  }
}
```

```json Professional Tone Filter
{
  "stage_type": "filter",
  "stage_id": "llm_filter",
  "parameters": {
    "model": "gpt-4o-mini",
    "criteria": "Include only documents with professional, formal tone suitable for business communication. Exclude casual, informal, or inappropriate content.",
    "content_field": "content"
  }
}
```

```json Factual Content Only
{
  "stage_type": "filter",
  "stage_id": "llm_filter",
  "parameters": {
    "model": "gpt-4o",
    "criteria": "Keep only factual, informative content. Remove: opinions without evidence, speculation, promotional content, and entertainment-focused material.",
    "explanation": true
  }
}
```
</CodeGroup>

## Writing Effective Criteria

### Good Criteria Examples

```
✓ "Keep documents about machine learning algorithms and their implementations"
✓ "Filter out content that is primarily promotional or marketing material"
✓ "Include only documents written in the last 5 years about cloud computing"
✓ "Keep technical documentation; remove blog posts and news articles"
```

### Poor Criteria Examples

```
✗ "Good documents" (too vague)
✗ "Relevant content" (not specific)
✗ "High quality" (subjective without definition)
```

<Tip>
  Be specific about what to include AND exclude. The LLM makes a binary keep/discard decision for each document.
</Tip>

## Output Schema

### Without Explanation

Documents that pass the filter are returned unchanged:

```json
{
  "document_id": "doc_123",
  "content": "Technical documentation about...",
  "metadata": {...}
}
```

### With Explanation

```json
{
  "document_id": "doc_123",
  "content": "Technical documentation about...",
  "metadata": {...},
  "llm_filter": {
    "passed": true,
    "explanation": "Document contains detailed technical information about API implementation."
  }
}
```

### Filtered Out (not in results)

Documents that don't match criteria are removed from the result set.

## Performance

| Metric | Value |
|--------|-------|
| **Latency** | 200-500ms per batch |
| **Batch size** | 10 documents default |
| **Token usage** | ~100 tokens per document |
| **Parallel** | Batches processed concurrently |

<Warning>
  LLM filtering is expensive and slow. Always apply `structured_filter` or use search `top_k` limits to reduce the document set before LLM filtering.
</Warning>

## Common Pipeline Patterns

### Search + Metadata Filter + LLM Filter

```json
[
  {
    "stage_type": "filter",
    "stage_id": "semantic_search",
    "parameters": {
      "query": "{{INPUT.query}}",
      "vector_index": "text_extractor_v1_embedding",
      "top_k": 50
    }
  },
  {
    "stage_type": "filter",
    "stage_id": "structured_filter",
    "parameters": {
      "conditions": {
        "field": "metadata.type",
        "operator": "eq",
        "value": "documentation"
      }
    }
  },
  {
    "stage_type": "filter",
    "stage_id": "llm_filter",
    "parameters": {
      "model": "gpt-4o-mini",
      "criteria": "Keep only documents that provide actionable, step-by-step instructions"
    }
  },
  {
    "stage_type": "reduce",
    "stage_id": "limit",
    "parameters": {
      "limit": 5
    }
  }
]
```

### Quality + Relevance Pipeline

```json
[
  {
    "stage_type": "filter",
    "stage_id": "hybrid_search",
    "parameters": {
      "query": "{{INPUT.query}}",
      "vector_index": "text_extractor_v1_embedding",
      "top_k": 30
    }
  },
  {
    "stage_type": "sort",
    "stage_id": "rerank",
    "parameters": {
      "model": "bge-reranker-v2-m3",
      "top_n": 15
    }
  },
  {
    "stage_type": "filter",
    "stage_id": "llm_filter",
    "parameters": {
      "model": "gpt-4o-mini",
      "criteria": "Keep only high-quality, authoritative sources. Remove: user-generated content without verification, outdated information (pre-2020), and incomplete documents."
    }
  }
]
```

## Cost Optimization

| Strategy | Impact |
|----------|--------|
| Pre-filter with metadata | Reduce documents before LLM |
| Use cheaper models | `gpt-4o-mini` vs `gpt-4o` |
| Increase batch size | Fewer API calls |
| Limit input documents | Use `top_k` in search |

## Error Handling

| Error | Behavior |
|-------|----------|
| LLM timeout | Retry once, then fail |
| Rate limit | Automatic backoff |
| Invalid model | Stage fails |
| Empty criteria | All documents pass |

## Related

- [Structured Filter](/retrieval/stages/structured-filter) - Metadata-based filtering
- [Rerank](/retrieval/stages/rerank) - Relevance-based ordering
- [LLM Enrichment](/retrieval/stages/llm-enrichment) - Extract data with LLM
